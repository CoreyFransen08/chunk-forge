# LlamaParse API Key (Required for high-quality PDF parsing)
# Get your API key from: https://cloud.llamaindex.ai/api-key
LLAMA_CLOUD_API_KEY=llx-your-api-key-here

# OpenAI API Key (Optional - for semantic chunking with OpenAI embeddings)
# If not provided, semantic chunking will use local models or fast mode
OPENAI_API_KEY=

# Cache Configuration (Optional)
# Directory for embedding cache (default: ./cache/embeddings)
EMBEDDING_CACHE_DIR=./cache/embeddings

# TTL for embedding cache in seconds (default: 604800 = 7 days)
EMBEDDING_CACHE_TTL=604800

# Directory for chunk result cache (default: ./cache/chunks)
CHUNK_CACHE_DIR=./cache/chunks

# TTL for chunk cache in seconds (default: 86400 = 1 day)
CHUNK_CACHE_TTL=86400

# Directory for parse result cache (default: ./cache/parses)
PARSE_CACHE_DIR=./cache/parses

# TTL for parse cache in seconds (default: 604800 = 7 days)
PARSE_CACHE_TTL=604800

# Parser Service Port (optional, defaults to 8000)
# PORT=8000
